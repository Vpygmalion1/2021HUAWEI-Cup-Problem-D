{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b1c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADMET性质预测\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import math\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,ShuffleSplit, GridSearchCV\n",
    "from sklearn.manifold import TSNE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score,precision_score, recall_score, f1_score, confusion_matrix,roc_curve, auc\n",
    "from scipy import stats\n",
    "import itertools\n",
    "sns.set_style('ticks')\n",
    "\n",
    "# # 1 导入数据\n",
    "ADMET = pd.read_excel('./数据/ADMET.xlsx')\n",
    "data = pd.read_excel('./数据/Molecular_Descriptor.xlsx')\n",
    "test_x = pd.read_excel('./数据/Molecular_Descriptor.xlsx',sheet_name='test')\n",
    "ADMET_test = pd.read_excel('./数据/ADMET.xlsx',sheet_name='test')\n",
    "\n",
    "X1_fea = list(pd.read_excel('./数据/Caco-2-51个特征排序.xlsx')['features'][:20])\n",
    "X2_fea = list(pd.read_excel('./数据/CYP3A4特征排序.xlsx')['features'][:20])\n",
    "X3_fea = list(pd.read_excel('./数据/hERG特征排序.xlsx')['features'][:20])\n",
    "X4_fea = list(pd.read_excel('./数据/HOB特征排序.xlsx')['features'][:20])\n",
    "X5_fea = list(pd.read_excel('./数据/MN特征排序.xlsx')['features'][:20])\n",
    "\n",
    "X1, X2, X3, X4, X5 = data[X1_fea], data[X2_fea], data[X3_fea], data[X4_fea], data[X5_fea]\n",
    "y1,y2,y3,y4,y5 = ADMET['Caco-2'], ADMET['CYP3A4'], ADMET['hERG'], ADMET['HOB'], ADMET['MN']\n",
    "X1_train,X1_test,y1_train,y1_test=train_test_split(np.array(X1),np.array(y1),test_size=0.2,shuffle=True)\n",
    "X2_train,X2_test,y2_train,y2_test=train_test_split(np.array(X2),np.array(y2),test_size=0.2,shuffle=True)\n",
    "X3_train,X3_test,y3_train,y3_test=train_test_split(np.array(X3),np.array(y3),test_size=0.2,shuffle=True)\n",
    "X4_train,X4_test,y4_train,y4_test=train_test_split(np.array(X4),np.array(y4),test_size=0.2,shuffle=True)\n",
    "X5_train,X5_test,y5_train,y5_test=train_test_split(np.array(X5),np.array(y5),test_size=0.2,shuffle=True)\n",
    "\n",
    "test_x1, test_x2, test_x3, test_x4, test_x5 = test_x[X1_fea], test_x[X2_fea], test_x[X3_fea], test_x[X4_fea], test_x[X5_fea]\n",
    "\n",
    "# # 2 模型训练\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.title(title,fontsize=18,fontweight='bold')\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0,fontsize=16,fontweight='bold')\n",
    "    plt.yticks(tick_marks, classes,fontsize=16,fontweight='bold')\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar()\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",fontsize=14)\n",
    "\n",
    "def train_model(X_train,y_train,X_test,y_test,save_path1=None,save_path2=None,save_path3 =None):\n",
    "    auc_score, pre_score, rec_score, f_score = {},{},{},{}\n",
    "    #逻辑斯蒂回归\n",
    "    LR = LogisticRegression(solver='newton-cg')\n",
    "    LR_score = LR.fit(X_train,y_train).predict_proba(X_test)\n",
    "    LR_fpr,LR_tpr,LR_threshold = roc_curve(y_test, LR_score[:,1])\n",
    "    LR_roc_auc = auc(LR_fpr,LR_tpr)\n",
    "    LR_pred = LR.predict(X_test)\n",
    "    auc_score['LR'] = roc_auc_score(y_test,LR_pred)\n",
    "    pre_score['LR'] = precision_score(y_test,LR_pred)\n",
    "    rec_score['LR'] = recall_score(y_test,LR_pred)\n",
    "    f_score['LR'] = f1_score(y_test,LR_pred)\n",
    "    #SVM\n",
    "    svc = SVC(kernel='linear')\n",
    "    svc_score = svc.fit(X_train,y_train).decision_function(X_test)\n",
    "    svc_fpr,svc_tpr,svc_threshold = roc_curve(y_test, svc_score) ###计算真正率和假正率\n",
    "    svc_roc_auc = auc(svc_fpr,svc_tpr)\n",
    "    svc_pred = svc.predict(X_test)\n",
    "    auc_score['SVC'] = roc_auc_score(y_test,svc_pred)\n",
    "    pre_score['SVC'] = precision_score(y_test,svc_pred)\n",
    "    rec_score['SVC'] = recall_score(y_test,svc_pred)\n",
    "    f_score['SVC'] = f1_score(y_test,svc_pred)\n",
    "    #RF\n",
    "    RF = RandomForestClassifier(random_state=5)\n",
    "    RF_score = RF.fit(X_train,y_train).predict_proba(X_test)\n",
    "    RF_fpr,RF_tpr,RF_threshold = roc_curve(y_test, RF_score[:,1]) ###计算真正率和假正率\n",
    "    RF_roc_auc = auc(RF_fpr,RF_tpr)\n",
    "    RF_pred = RF.predict(X_test)\n",
    "    auc_score['RF'] = roc_auc_score(y_test,RF_pred)\n",
    "    pre_score['RF'] = precision_score(y_test,RF_pred)\n",
    "    rec_score['RF'] = recall_score(y_test,RF_pred)\n",
    "    f_score['RF'] = f1_score(y_test,RF_pred)\n",
    "    # XGB\n",
    "    xgb= XGBClassifier(learning_rate=0.1,n_estimators=1000,max_depth=5, min_child_weight=1,gamma=0,subsample=0.6,random_state=5,colsample_bytree=0.8,objective= 'binary:logistic',scale_pos_weight=1,seed=27)\n",
    "    xgb_score = xgb.fit(X_train,y_train).predict_proba(X_test)\n",
    "    xgb_fpr,xgb_tpr,xgb_threshold = roc_curve(y_test, xgb_score[:,1]) \n",
    "    xgb_roc_auc = auc(xgb_fpr,xgb_tpr)\n",
    "    xgb_pred = xgb.predict(X_test)\n",
    "    auc_score['XGBoost'] = roc_auc_score(y_test,xgb_pred)\n",
    "    pre_score['XGBoost'] = precision_score(y_test,xgb_pred)\n",
    "    rec_score['XGBoost'] = recall_score(y_test,xgb_pred)\n",
    "    f_score['XGBoost'] = f1_score(y_test,xgb_pred)\n",
    "    # GBDT\n",
    "    gbdt = GradientBoostingClassifier()\n",
    "    gbdt_score = gbdt.fit(X_train,y_train).predict_proba(X_test)\n",
    "    gbdt_fpr,gbdt_tpr,gbdt_threshold = roc_curve(y_test, gbdt_score[:,1]) \n",
    "    gbdt_roc_auc = auc(gbdt_fpr,gbdt_tpr)\n",
    "    gbdt_pred = gbdt.predict(X_test)\n",
    "    auc_score['GBDT'] = roc_auc_score(y_test,gbdt_pred)\n",
    "    pre_score['GBDT'] = precision_score(y_test,gbdt_pred)\n",
    "    rec_score['GBDT'] = recall_score(y_test,gbdt_pred)\n",
    "    f_score['GBDT'] = f1_score(y_test,gbdt_pred)\n",
    "    # lgb\n",
    "    gmb = lgb.LGBMClassifier(num_leaves=30, learning_rate=0.05, n_estimators=200)\n",
    "    gmb_score = gmb.fit(X_train,y_train).predict_proba(X_test)\n",
    "    gmb_fpr,gmb_tpr,gmb_threshold = roc_curve(y_test, gmb_score[:,1]) \n",
    "    gmb_roc_auc = auc(gmb_fpr,gmb_tpr)\n",
    "    gmb_pred = gmb.predict(X_test)\n",
    "    auc_score['LightGBM'] = roc_auc_score(y_test,gmb_pred)\n",
    "    pre_score['LightGBM'] = precision_score(y_test,gmb_pred)\n",
    "    rec_score['LightGBM'] = recall_score(y_test,gmb_pred)\n",
    "    f_score['LightGBM'] = f1_score(y_test,gmb_pred)\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.subplot(231)\n",
    "    gmb_matrix = confusion_matrix(y_test,gmb_pred)\n",
    "    print(\"Recall metric in the testing dataset: \",gmb_matrix[1,1]/(gmb_matrix[1,0]+ gmb_matrix[1,1]))\n",
    "\n",
    "    class_names = [0,1]\n",
    "    plot_confusion_matrix(gmb_matrix,classes=class_names,title='LightGBM') \n",
    "    plt.ylabel('True label',fontsize=18,fontweight='bold')\n",
    "    \n",
    "    plt.subplot(232)\n",
    "    xgb_matrix = confusion_matrix(y_test,xgb_pred)\n",
    "    print(\"Recall metric in the testing dataset: \",xgb_matrix[1,1]/(xgb_matrix[1,0]+xgb_matrix [1,1]))\n",
    "    class_names = [0,1]\n",
    "    plot_confusion_matrix(xgb_matrix,classes=class_names ,title='XGBoost')\n",
    "    \n",
    "    plt.subplot(233)\n",
    "    RF_matrix = confusion_matrix(y_test,RF_pred)\n",
    "    print(\"Recall metric in the testing dataset: \",RF_matrix[1,1]/(RF_matrix[1,0]+RF_matrix [1,1]))\n",
    "\n",
    "    class_names = [0,1]\n",
    "    plot_confusion_matrix(RF_matrix,classes=class_names ,title='RandomForest')\n",
    "    \n",
    "    plt.subplot(234)\n",
    "    svc_matrix = confusion_matrix(y_test,svc_pred)\n",
    "    print(\"Recall metric in the testing dataset: \",svc_matrix[1,1]/(svc_matrix[1,0]+svc_matrix [1,1]))\n",
    "\n",
    "    class_names = [0,1]\n",
    "    plot_confusion_matrix(svc_matrix,classes=class_names,title='SVM')\n",
    "    plt.ylabel('True label',fontsize=18,fontweight='bold')\n",
    "    plt.xlabel('Predicted label',fontsize=18,fontweight='bold')\n",
    "    \n",
    "    plt.subplot(235)\n",
    "    gbdt_matrix = confusion_matrix(y_test,gbdt_pred)\n",
    "\n",
    "    print(\"Recall metric in the testing dataset: \",gbdt_matrix[1,1]/(gbdt_matrix[1,0]+ gbdt_matrix[1,1]))\n",
    "\n",
    "    class_names = [0,1]\n",
    "    plot_confusion_matrix(gbdt_matrix,classes=class_names,title='GBDT')  \n",
    "    plt.xlabel('Predicted label',fontsize=18,fontweight='bold')\n",
    "    \n",
    "    plt.subplot(236)\n",
    "    lr_matrix = confusion_matrix(y_test,LR_pred)\n",
    "    print(\"Recall metric in the testing dataset: \",lr_matrix[1,1]/(lr_matrix[1,0]+lr_matrix[1,1]))\n",
    "    class_names = [0,1]\n",
    "    plot_confusion_matrix(lr_matrix,classes=class_names,title='Logistic Regression')\n",
    "    plt.xlabel('Predicted label',fontsize=18,fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path1,dpi=100)\n",
    "    plt.show()\n",
    "    lw = 3\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(svc_fpr, svc_tpr, color='green', lw=lw, label='SVM roc curve (area = %0.2f)' % svc_roc_auc)\n",
    "    plt.plot(gbdt_fpr, gbdt_tpr, color='deeppink', lw=lw, label='GBDT roc curve (area = %0.2f)' % gbdt_roc_auc)\n",
    "    plt.plot(LR_fpr, LR_tpr, color='gray', lw=lw, label='Logistic regression roc curve (area = %0.2f)' % LR_roc_auc)\n",
    "    plt.plot(gmb_fpr, gmb_tpr, color='red', lw=lw, label='LightGBM roc curve (area = %0.2f)' % gmb_roc_auc) \n",
    "    plt.plot(xgb_fpr, xgb_tpr, color='gold', lw=lw, label='XGBoost roc curve (area = %0.2f)' % xgb_roc_auc)\n",
    "    plt.plot(RF_fpr, RF_tpr, color='royalblue', lw=lw, label='RandomForest roc curve (area = %0.2f)' % RF_roc_auc) \n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate',fontsize=18,fontweight='bold')\n",
    "    plt.ylabel('True Positive Rate',fontsize=18,fontweight='bold')\n",
    "    plt.title('ROC_AUC',fontsize=18,fontweight='bold')\n",
    "    plt.legend(loc=4,fontsize=12)\n",
    "    plt.savefig(save_path2,dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(gmb_fpr[45:73], gmb_tpr[45:73], color='red', lw=lw, label='LightGBM roc curve (area = %0.2f)' % gmb_roc_auc) \n",
    "    plt.plot(xgb_fpr[45:70], xgb_tpr[45:70], color='gold', lw=lw, label='XGBoost roc curve (area = %0.2f)' % xgb_roc_auc)\n",
    "    plt.plot(RF_fpr[35:60], RF_tpr[35:60], color='royalblue', lw=lw, label='RandomForest roc curve (area = %0.2f)' % RF_roc_auc)\n",
    "    plt.plot(gbdt_fpr[50:84], gbdt_tpr[50:84], color='deeppink', lw=lw, label='GBDT roc curve (area = %0.2f)' % gbdt_roc_auc)\n",
    "    plt.xlabel('False Positive Rate',fontsize=18,fontweight='bold')\n",
    "    plt.ylabel('True Positive Rate',fontsize=18,fontweight='bold')\n",
    "    plt.title('ROC_AUC',fontsize=18,fontweight='bold')\n",
    "    plt.savefig(save_path3,dpi=100)\n",
    "    plt.show()\n",
    "    return auc_score,pre_score,rec_score,f_score\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    save_path1 = './HOB.tif' \n",
    "    save_path2 = './HOB_roc1.tif' \n",
    "    save_path3 = './HOB_roc2.tif' \n",
    "    x4_auc, x4_pre,x4_rec,x4_f1 =train_model(X4_train,y4_train,X4_test,y4_test,save_path1, save_path2,save_path3)\n",
    "\n",
    "coca = RandomForestClassifier(random_state=5)\n",
    "coca.fit(X1,y1)\n",
    "copy_model = XGBClassifier(learning_rate=0.1,n_estimators=1000,max_depth=5,min_child_weight=1,gamma=0,subsample=0.6,random_state=5,colsample_bytree=0.8,objective= 'binary:logistic',scale_pos_weight=1,seed=27)\n",
    "copy_model.fit(X2,y2)\n",
    "herg_model = XGBClassifier(learning_rate=0.1,n_estimators=1000,max_depth=5,min_child_weight=1,gamma=0,subsample=0.6,random_state=5,colsample_bytree=0.8,objective= 'binary:logistic',scale_pos_weight=1,seed=27)\n",
    "herg_model.fit(X3,y3)\n",
    "hob_model = lgb.LGBMClassifier(num_leaves=30, learning_rate=0.05, n_estimators=200)\n",
    "hob_model.fit(X4,y4)\n",
    "mn=XGBClassifier(learning_rate=0.1,n_estimators=1000,max_depth=5,min_child_weight=1,gamma=0,subsample=0.6,random_state=5,colsample_bytree=0.8,objective='binary:logistic',scale_pos_weight=1,seed=27)\n",
    "mn.fit(X5,y5)\n",
    "\n",
    "caco_pred = coca.predict(test_x1)\n",
    "copy_pred = copy_model.predict(test_x2)\n",
    "herg_pred = herg_model.predict(test_x3)\n",
    "hob_pred = hob_model.predict(test_x4)\n",
    "mn_pred = mn.predict(test_x5)\n",
    "\n",
    "ADMET_test['Caco-2'] =  caco_pred\n",
    "ADMET_test['CYP3A4'] =  copy_pred\n",
    "ADMET_test['hERG'] =  herg_pred\n",
    "ADMET_test['HOB'] =  hob_pred\n",
    "ADMET_test['MN'] =  mn_pred\n",
    "\n",
    "ADMET_test.to_excel('./prediction2.xlsx',index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
